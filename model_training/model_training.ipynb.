{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utw_7KG91lmS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/sample_data/combined_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Handle missing values (drop rows with missing values)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Step 2: Standardize column names (replace special characters with underscores)\n",
        "df.columns = df.columns.str.replace(r'\\W+', '_', regex=True)\n",
        "\n",
        "# Step 3: Convert numerical columns to integers (excluding target column)\n",
        "numerical_cols = df.columns[:-1]  # All except the last column \"Disorder\"\n",
        "df[numerical_cols] = df[numerical_cols].astype(int)\n",
        "\n",
        "# Step 4: Encode categorical target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Disorder\"] = label_encoder.fit_transform(df[\"Disorder\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApT14p1r12UJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier,AdaBoostClassifier\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from collections import Counter\n",
        "\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "from scipy import stats as st\n",
        "\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6otL5mm15Es"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__omCXZi2CW8"
      },
      "outputs": [],
      "source": [
        "X=df.iloc[:,0:28]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_-NBlrI2E_N"
      },
      "outputs": [],
      "source": [
        "y=df.iloc[:,28]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY4tTzj12Ge2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPsZhG902IXY"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngWfdC2h2LjI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(dict(zip(unique, counts)))  # Shows class distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x7VSA7uS2Ncq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
        "param_grid = {\n",
        " 'bootstrap': [True],\n",
        " 'max_depth': [80, 90, 100, 110],\n",
        " 'max_features': [2, 3],\n",
        " 'min_samples_leaf': [3, 4, 5],\n",
        " 'min_samples_split': [8, 10, 12],\n",
        " 'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "rfclassifier = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
        " cv = 5, n_jobs = -1, verbose = 2)\n",
        "rfclassifier.fit(x_train, y_train)\n",
        "rfclassifier.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8CoGlQ0L2RHk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, average_precision_score, accuracy_score, f1_score\n",
        "y_pred = rfclassifier.predict(x_test)\n",
        "y_proba = rfclassifier.predict_proba(x_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KVJYxW_k2TuC"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    hamming_loss, jaccard_score, log_loss, matthews_corrcoef,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    precision_score, recall_score, accuracy_score, f1_score\n",
        ")\n",
        "\n",
        "print('\\n')\n",
        "accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
        "precision = round(precision_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "recall = round(recall_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "jaccard = round(jaccard_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Jaccard Score:\", jaccard)\n",
        "\n",
        "# AUC Score (One-vs-Rest)\n",
        "# Get all possible class labels\n",
        "classes = np.unique(y_train)  # Ensure all classes are included\n",
        "\n",
        "# Binarize y_test\n",
        "y_test_binarized = label_binarize(y_test, classes=classes)\n",
        "\n",
        "# Compute AUC correctly\n",
        "auc = roc_auc_score(y_test_binarized, y_proba, average=\"weighted\", multi_class=\"ovr\")\n",
        "print('AUC:', round(auc, 2))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Actual values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.savefig(\"Confusion_Matrix_RF.png\", dpi=800, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve for Multiclass\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(len(set(y_test))):  # Loop through each class\n",
        "    precision, recall, _ = precision_recall_curve(y_test == i, y_proba[:, i])\n",
        "    plt.plot(recall, precision, label=f'Class {i}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.legend()\n",
        "plt.title(\"Precision-Recall Curve for Multiclass Classification\")\n",
        "plt.grid()\n",
        "plt.savefig(\"PR_curve_multiclass_RF.png\", dpi=800, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Get unique classes from training set\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "# Ensure y_test has the same number of classes\n",
        "print(\"Unique classes in y_train:\", classes)\n",
        "print(\"Unique classes in y_test:\", np.unique(y_test))\n",
        "\n",
        "# Compute log loss with explicit class labels\n",
        "print(\"Log Loss:\", log_loss(y_test, y_proba, labels=classes))\n",
        "# Matthews Correlation Coefficient\n",
        "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "# Hamming Loss\n",
        "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q1fcJSqr2byR"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'penalty': ['l2'],  # 'l1' can only be used with 'saga'\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'solver': ['lbfgs', 'saga'],  # Compatible solvers for multinomial logistic regression\n",
        "    'multi_class': ['multinomial']  # Enables proper handling of multiclass problems\n",
        "}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "lr = LogisticRegression(class_weight=\"balanced\")\n",
        "\n",
        "# Instantiate GridSearchCV\n",
        "lrClassifier = GridSearchCV(estimator=lr, param_grid=param_grid,\n",
        "                            cv=3, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit model\n",
        "lrClassifier.fit(x_train, y_train)\n",
        "\n",
        "# Get best parameters\n",
        "print(\"Best Parameters:\", lrClassifier.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sF1XZmMO2cM2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, average_precision_score, accuracy_score, f1_score\n",
        "y_pred = lrClassifier.predict(x_test)\n",
        "y_proba = lrClassifier.predict_proba(x_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    hamming_loss, jaccard_score, log_loss, matthews_corrcoef,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    precision_score, recall_score, accuracy_score, f1_score\n",
        ")\n",
        "\n",
        "print('\\n')\n",
        "accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
        "precision = round(precision_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "recall = round(recall_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "jaccard = round(jaccard_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Jaccard Score:\", jaccard)\n",
        "\n",
        "# AUC Score (One-vs-Rest)\n",
        "# Get all possible class labels\n",
        "classes = np.unique(y_train)  # Ensure all classes are included\n",
        "\n",
        "# Binarize y_test\n",
        "y_test_binarized = label_binarize(y_test, classes=classes)\n",
        "\n",
        "# Compute AUC correctly\n",
        "auc = roc_auc_score(y_test_binarized, y_proba, average=\"weighted\", multi_class=\"ovr\")\n",
        "print('AUC:', round(auc, 2))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Actual values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.savefig(\"Confusion_Matrix_RF.png\", dpi=800, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve for Multiclass\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(len(set(y_test))):  # Loop through each class\n",
        "    precision, recall, _ = precision_recall_curve(y_test == i, y_proba[:, i])\n",
        "    plt.plot(recall, precision, label=f'Class {i}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.legend()\n",
        "plt.title(\"Precision-Recall Curve for Multiclass Classification\")\n",
        "plt.grid()\n",
        "plt.savefig(\"PR_curve_multiclass_RF.png\", dpi=800, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Get unique classes from training set\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "# Ensure y_test has the same number of classes\n",
        "print(\"Unique classes in y_train:\", classes)\n",
        "print(\"Unique classes in y_test:\", np.unique(y_test))\n",
        "\n",
        "# Compute log loss with explicit class labels\n",
        "print(\"Log Loss:\", log_loss(y_test, y_proba, labels=classes))\n",
        "# Matthews Correlation Coefficient\n",
        "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "# Hamming Loss\n",
        "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UVIEC1hb2dzL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, jaccard_score,\n",
        "    log_loss, matthews_corrcoef, confusion_matrix, roc_auc_score,\n",
        "    roc_curve, precision_recall_curve, classification_report\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [4, 6, 10, 20, 30, 50, 70, 100],  # Reduced for efficiency\n",
        "    'min_samples_split': range(10, 500, 50),  # Step increased to reduce computation time\n",
        "    'splitter': ['best', 'random'],\n",
        "    'min_samples_leaf': [1, 5, 10, 15],\n",
        "    'max_features': ['log2', 'sqrt', 'auto']\n",
        "}\n",
        "\n",
        "# Initialize Decision Tree Model\n",
        "dt = DecisionTreeClassifier(random_state=42,class_weight=\"balanced\")\n",
        "\n",
        "# Grid Search with 3-Fold Cross Validation\n",
        "dtClassifier = GridSearchCV(estimator=dt, param_grid=param_grid,\n",
        "                            cv=3, n_jobs=-1, verbose=2)\n",
        "dtClassifier.fit(x_train, y_train)\n",
        "\n",
        "# Get best hyperparameters\n",
        "print(\"Best Parameters:\", dtClassifier.best_params_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6E-S2fon2ftc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, average_precision_score, accuracy_score, f1_score\n",
        "y_pred = dtClassifier.predict(x_test)\n",
        "y_proba = dtClassifier.predict_proba(x_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    hamming_loss, jaccard_score, log_loss, matthews_corrcoef,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    precision_score, recall_score, accuracy_score, f1_score\n",
        ")\n",
        "\n",
        "print('\\n')\n",
        "accuracy = round(accuracy_score(y_test, y_pred), 2)\n",
        "precision = round(precision_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "recall = round(recall_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "jaccard = round(jaccard_score(y_test, y_pred, average=\"weighted\"), 2)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Jaccard Score:\", jaccard)\n",
        "\n",
        "# AUC Score (One-vs-Rest)\n",
        "# Get all possible class labels\n",
        "classes = np.unique(y_train)  # Ensure all classes are included\n",
        "\n",
        "# Binarize y_test\n",
        "y_test_binarized = label_binarize(y_test, classes=classes)\n",
        "\n",
        "# Compute AUC correctly\n",
        "auc = roc_auc_score(y_test_binarized, y_proba, average=\"weighted\", multi_class=\"ovr\")\n",
        "print('AUC:', round(auc, 2))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Actual values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.title(\"Confusion Matrix - decision tree\")\n",
        "plt.savefig(\"Confusion_Matrix_RF.png\", dpi=800, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve for Multiclass\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(len(set(y_test))):  # Loop through each class\n",
        "    precision, recall, _ = precision_recall_curve(y_test == i, y_proba[:, i])\n",
        "    plt.plot(recall, precision, label=f'Class {i}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.legend()\n",
        "plt.title(\"Precision-Recall Curve for Multiclass Classification\")\n",
        "plt.grid()\n",
        "plt.savefig(\"PR_curve_multiclass_RF.png\", dpi=800, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Get unique classes from training set\n",
        "classes = np.unique(y_train)\n",
        "\n",
        "# Ensure y_test has the same number of classes\n",
        "print(\"Unique classes in y_train:\", classes)\n",
        "print(\"Unique classes in y_test:\", np.unique(y_test))\n",
        "\n",
        "# Compute log loss with explicit class labels\n",
        "print(\"Log Loss:\", log_loss(y_test, y_proba, labels=classes))\n",
        "# Matthews Correlation Coefficient\n",
        "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "# Hamming Loss\n",
        "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVPfeNxbvXIK",
        "outputId": "270be501-73f3-4066-c1ae-49476aab13a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PermutationExplainer explainer:  88%|████████▊ | 484/549 [19:40<02:39,  2.45s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fa773f23a407>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ):\n\u001b[1;32m     99\u001b[0m         \u001b[0;34m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# evaluate the masked model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"supports_delta_masking\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# we need to convert from delta masking to a full masking call because we were given a delta masking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_delta_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# joined_masked_inputs = self._stack_inputs(all_masked_inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubset_masked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0m_assert_output_input_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_masked_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shap/models/_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mis_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tensor\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \"\"\"\n\u001b[1;32m    597\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_search_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    955\u001b[0m         ]\n\u001b[1;32m    956\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import shap\n",
        "explainer = shap.Explainer(rfclassifier.predict, x_train)\n",
        "shap_values = explainer(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eCKMKK8XvaOj"
      },
      "outputs": [],
      "source": [
        "fig=plt.figure()\n",
        "fig=shap.plots.beeswarm(shap_values, max_display=25,show=False)\n",
        "plt.savefig(\"BeeSwarm1.png\", dpi=700,bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TdvwJb-jvcWz"
      },
      "outputs": [],
      "source": [
        "fig=shap.summary_plot(shap_values, x_train, plot_type=\"bar\",show=False)\n",
        "plt.savefig(\"BarChartSHAP.png\", dpi=100,bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q4-U1HL8vdzD"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "from lime import lime_tabular\n",
        "interpretor = lime_tabular.LimeTabularExplainer(\n",
        " training_data=np.array(x_train),\n",
        " feature_names=x_train.columns,\n",
        " mode='classification'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0Oakg8lov6rx"
      },
      "outputs": [],
      "source": [
        "exp = interpretor.explain_instance(\n",
        " data_row=x_test.iloc[12], ##new data\n",
        " predict_fn=rfclassifier.predict_proba\n",
        ")\n",
        "exp.save_to_file('LIME1.html')\n",
        "fig = exp.as_pyplot_figure()\n",
        "fig.savefig('lime_report.png')\n",
        "fig=exp.show_in_notebook(show_table=True)\n",
        "plt.savefig(\"LIMESurvived.png\", dpi=100,bbox_inches = 'tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pH7ydoLkv_PO"
      },
      "outputs": [],
      "source": [
        "with plt.style.context(\"ggplot\"):\n",
        " exp.as_pyplot_figure()\n",
        " plt.savefig(\"LIME1.png\", dpi=600,bbox_inches = 'tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "op9DYUN9wFnV"
      },
      "outputs": [],
      "source": [
        "exp = interpretor.explain_instance(\n",
        " data_row=x_test.iloc[25], ##new data\n",
        " predict_fn=rfclassifier.predict_proba\n",
        ")\n",
        "fig=exp.show_in_notebook(show_table=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tg7_xF0MwG4O"
      },
      "outputs": [],
      "source": [
        "with plt.style.context(\"ggplot\"):\n",
        " exp.as_pyplot_figure()\n",
        " plt.savefig(\"LIME2.png\", dpi=600,bbox_inches = 'tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eGLNwTy42hKo"
      },
      "outputs": [],
      "source": [
        "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "print(\"Target Variable Mapping:\", label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jTcka13J2jum"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the attributes for user input\n",
        "attributes = [\n",
        "     \"age\", \"feeling_nervous\", \"panic\", \"breathing_rapidly\", \"sweating\", \"trouble_in_concentration\", \"having_trouble_in_sleeping\", \"having_trouble_with_work\", \"hopelessness\", \"anger\", \"over_react\", \"change_in_eating\", \"suicidal_thought\", \"feeling_tired\", \"close_friend\", \"social_media_addiction\", \"weight_gain\", \"introvert\", \"popping_up_stressful_memory\", \"having_nightmares\", \"avoids_people_or_activities\", \"feeling_negative\", \"trouble_concentrating\", \"blamming_yourself\", \"hallucinations\", \"repetitive_behaviour\", \"seasonally\", \"increased_energy\"\n",
        "]\n",
        "\n",
        "# Take user input\n",
        "print(\"Enter values for the following attributes:\")\n",
        "user_input = []\n",
        "for attr in attributes:\n",
        "    value = float(input(f\"{attr}: \"))  # Convert input to float\n",
        "    user_input.append(value)\n",
        "\n",
        "# Convert input into a NumPy array and reshape it for model prediction\n",
        "user_input_array = np.array(user_input).reshape(1, -1)\n",
        "\n",
        "# Predict using the best model\n",
        "best_model=lrClassifier\n",
        "predicted_class = best_model.predict(user_input_array)\n",
        "\n",
        "print(\"\\nPredicted Target Variable:\", predicted_class[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S9MjYsAC7GAc"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Confirm the model type\n",
        "print(\"Model type:\", type(best_model))\n",
        "\n",
        "# Try saving directly\n",
        "try:\n",
        "    joblib.dump(best_model, 'mental_disorder_model.pkl')\n",
        "    joblib.dump(label_encoder, 'encoder.pkl')\n",
        "    print(\"Model saved successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"Error saving model:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YoDQyB6yCNP_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
